Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 256.839776
Pre-training layer 0, epoch 1, cost 138.927393
Pre-training layer 0, epoch 2, cost 129.925621
Pre-training layer 0, epoch 3, cost 126.013355
Pre-training layer 0, epoch 4, cost 121.988744
Pre-training layer 0, epoch 5, cost 118.678461
Pre-training layer 0, epoch 6, cost 116.359167
Pre-training layer 0, epoch 7, cost 115.448800
Pre-training layer 0, epoch 8, cost 113.791495
Pre-training layer 0, epoch 9, cost 112.116213
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98026 acc, 0.98201 prec, 0.98913 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 152.467195
Pre-training layer 0, epoch 1, cost 109.205501
Pre-training layer 0, epoch 2, cost 105.385222
Pre-training layer 0, epoch 3, cost 103.251825
Pre-training layer 0, epoch 4, cost 101.792936
Pre-training layer 0, epoch 5, cost 100.875665
Pre-training layer 0, epoch 6, cost 100.316066
Pre-training layer 0, epoch 7, cost 99.657902
Pre-training layer 0, epoch 8, cost 99.315397
Pre-training layer 0, epoch 9, cost 99.038886
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.96053 acc, 0.98214 prec, 0.97865 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 152.587418
Pre-training layer 0, epoch 1, cost 109.722721
Pre-training layer 0, epoch 2, cost 105.817758
Pre-training layer 0, epoch 3, cost 103.669403
Pre-training layer 0, epoch 4, cost 102.226437
Pre-training layer 0, epoch 5, cost 101.341975
Pre-training layer 0, epoch 6, cost 100.664371
Pre-training layer 0, epoch 7, cost 100.149678
Pre-training layer 0, epoch 8, cost 99.624173
Pre-training layer 0, epoch 9, cost 99.323270
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.96382 acc, 0.98524 prec, 0.97982 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 210.177587
Pre-training layer 0, epoch 1, cost 127.376958
Pre-training layer 0, epoch 2, cost 121.456349
Pre-training layer 0, epoch 3, cost 117.183271
Pre-training layer 0, epoch 4, cost 114.967306
Pre-training layer 0, epoch 5, cost 112.754741
Pre-training layer 0, epoch 6, cost 111.821991
Pre-training layer 0, epoch 7, cost 110.569680
Pre-training layer 0, epoch 8, cost 109.085284
Pre-training layer 0, epoch 9, cost 108.366025
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.96370 acc, 0.98901 prec, 0.98004 f1
SDA (1 layer(s), 0.00 corruption level) performance:
- Accuracy: DT 0.96708 (+/- 0.01545) || SVM-RBF 0.94981 (+/- 0.02799)
- Precision: DT 0.98460 (+/- 0.00571) || SVM-RBF 0.94659 (+/- 0.03563)
- F1: DT 0.98191 (+/- 0.00841) || SVM-RBF 0.97156 (+/- 0.01595) 
