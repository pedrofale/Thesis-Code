Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 253.217697
Pre-training layer 0, epoch 1, cost 143.857055
Pre-training layer 0, epoch 2, cost 134.647431
Pre-training layer 0, epoch 3, cost 129.921690
Pre-training layer 0, epoch 4, cost 125.581097
Pre-training layer 0, epoch 5, cost 121.189147
Pre-training layer 0, epoch 6, cost 118.474628
Pre-training layer 0, epoch 7, cost 117.220785
Pre-training layer 0, epoch 8, cost 116.212352
Pre-training layer 0, epoch 9, cost 114.887193
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98026 acc, 0.98561 prec, 0.98917 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 150.168729
Pre-training layer 0, epoch 1, cost 108.059033
Pre-training layer 0, epoch 2, cost 104.168772
Pre-training layer 0, epoch 3, cost 102.262943
Pre-training layer 0, epoch 4, cost 101.136754
Pre-training layer 0, epoch 5, cost 100.426901
Pre-training layer 0, epoch 6, cost 99.951683
Pre-training layer 0, epoch 7, cost 99.398603
Pre-training layer 0, epoch 8, cost 99.047664
Pre-training layer 0, epoch 9, cost 98.798470
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98355 acc, 0.98571 prec, 0.99102 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 149.744670
Pre-training layer 0, epoch 1, cost 108.148736
Pre-training layer 0, epoch 2, cost 104.231315
Pre-training layer 0, epoch 3, cost 102.399581
Pre-training layer 0, epoch 4, cost 101.311337
Pre-training layer 0, epoch 5, cost 100.733977
Pre-training layer 0, epoch 6, cost 100.208867
Pre-training layer 0, epoch 7, cost 99.761737
Pre-training layer 0, epoch 8, cost 99.550556
Pre-training layer 0, epoch 9, cost 99.365060
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98355 acc, 0.99262 prec, 0.99079 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 166.399225
Pre-training layer 0, epoch 1, cost 111.561297
Pre-training layer 0, epoch 2, cost 106.914596
Pre-training layer 0, epoch 3, cost 104.447126
Pre-training layer 0, epoch 4, cost 102.938217
Pre-training layer 0, epoch 5, cost 101.851232
Pre-training layer 0, epoch 6, cost 101.191124
Pre-training layer 0, epoch 7, cost 100.414441
Pre-training layer 0, epoch 8, cost 100.033171
Pre-training layer 0, epoch 9, cost 99.530156
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98350 acc, 0.99267 prec, 0.99086 f1
SDA (1 layer(s), 0.10 corruption level) performance:
- Accuracy: DT 0.98272 (+/- 0.00283) || SVM-RBF 0.93910 (+/- 0.03673)
- Precision: DT 0.98915 (+/- 0.00698) || SVM-RBF 0.93391 (+/- 0.04035)
- F1: DT 0.99046 (+/- 0.00150) || SVM-RBF 0.96525 (+/- 0.02118) 
