Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 370.982364
Pre-training layer 0, epoch 1, cost 103.355192
Pre-training layer 0, epoch 2, cost 101.690884
Pre-training layer 0, epoch 3, cost 101.045125
Pre-training layer 0, epoch 4, cost 100.704441
Pre-training layer 0, epoch 5, cost 100.495327
Pre-training layer 0, epoch 6, cost 100.354744
Pre-training layer 0, epoch 7, cost 100.254189
Pre-training layer 0, epoch 8, cost 100.178959
Pre-training layer 0, epoch 9, cost 100.120721
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.64145 acc, 0.64388 prec, 0.76660 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 338.833521
Pre-training layer 0, epoch 1, cost 101.765763
Pre-training layer 0, epoch 2, cost 100.079894
Pre-training layer 0, epoch 3, cost 99.403761
Pre-training layer 0, epoch 4, cost 98.981709
Pre-training layer 0, epoch 5, cost 98.771023
Pre-training layer 0, epoch 6, cost 98.629336
Pre-training layer 0, epoch 7, cost 98.527967
Pre-training layer 0, epoch 8, cost 98.452119
Pre-training layer 0, epoch 9, cost 98.393401
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.08882 acc, 0.01071 prec, 0.02120 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 248.902517
Pre-training layer 0, epoch 1, cost 101.951720
Pre-training layer 0, epoch 2, cost 100.308572
Pre-training layer 0, epoch 3, cost 99.670577
Pre-training layer 0, epoch 4, cost 99.332943
Pre-training layer 0, epoch 5, cost 99.127020
Pre-training layer 0, epoch 6, cost 98.987813
Pre-training layer 0, epoch 7, cost 98.888396
Pre-training layer 0, epoch 8, cost 98.814114
Pre-training layer 0, epoch 9, cost 98.756675
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.93421 acc, 0.94465 prec, 0.96241 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 233.404959
Pre-training layer 0, epoch 1, cost 100.709012
Pre-training layer 0, epoch 2, cost 99.069206
Pre-training layer 0, epoch 3, cost 98.432350
Pre-training layer 0, epoch 4, cost 98.096303
Pre-training layer 0, epoch 5, cost 97.890147
Pre-training layer 0, epoch 6, cost 97.751554
Pre-training layer 0, epoch 7, cost 97.652425
Pre-training layer 0, epoch 8, cost 97.578264
Pre-training layer 0, epoch 9, cost 97.520853
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.44554 acc, 0.40659 prec, 0.56923 f1
SDA (1 layer(s), 0.00 corruption level) performance:
- Accuracy: DT 0.52750 (+/- 0.61446) || SVM-RBF 0.49021 (+/- 0.80261)
- Precision: DT 0.50146 (+/- 0.68303) || SVM-RBF 0.49096 (+/- 0.98204)
- F1: DT 0.57986 (+/- 0.70244) || SVM-RBF 0.47116 (+/- 0.94232) 
