Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 140.436078
Pre-training layer 0, epoch 1, cost 102.833704
Pre-training layer 0, epoch 2, cost 101.447020
Pre-training layer 0, epoch 3, cost 100.644106
Pre-training layer 0, epoch 4, cost 100.147027
Pre-training layer 0, epoch 5, cost 99.820369
Pre-training layer 0, epoch 6, cost 99.552585
Pre-training layer 0, epoch 7, cost 99.362518
Pre-training layer 0, epoch 8, cost 99.191397
Pre-training layer 0, epoch 9, cost 99.108254
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98684 acc, 0.98921 prec, 0.99278 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 137.930975
Pre-training layer 0, epoch 1, cost 100.757530
Pre-training layer 0, epoch 2, cost 99.544084
Pre-training layer 0, epoch 3, cost 98.805289
Pre-training layer 0, epoch 4, cost 98.304373
Pre-training layer 0, epoch 5, cost 97.966806
Pre-training layer 0, epoch 6, cost 97.749387
Pre-training layer 0, epoch 7, cost 97.589604
Pre-training layer 0, epoch 8, cost 97.420897
Pre-training layer 0, epoch 9, cost 97.313385
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98684 acc, 0.99643 prec, 0.99288 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 138.019440
Pre-training layer 0, epoch 1, cost 101.452392
Pre-training layer 0, epoch 2, cost 100.079667
Pre-training layer 0, epoch 3, cost 99.220745
Pre-training layer 0, epoch 4, cost 98.772416
Pre-training layer 0, epoch 5, cost 98.454379
Pre-training layer 0, epoch 6, cost 98.194890
Pre-training layer 0, epoch 7, cost 98.009339
Pre-training layer 0, epoch 8, cost 97.853763
Pre-training layer 0, epoch 9, cost 97.763092
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.97368 acc, 0.97786 prec, 0.98513 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 136.799366
Pre-training layer 0, epoch 1, cost 100.373128
Pre-training layer 0, epoch 2, cost 98.911364
Pre-training layer 0, epoch 3, cost 98.118939
Pre-training layer 0, epoch 4, cost 97.540190
Pre-training layer 0, epoch 5, cost 97.213123
Pre-training layer 0, epoch 6, cost 96.966084
Pre-training layer 0, epoch 7, cost 96.801361
Pre-training layer 0, epoch 8, cost 96.624397
Pre-training layer 0, epoch 9, cost 96.517026
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98350 acc, 0.99634 prec, 0.99089 f1
SDA (1 layer(s), 0.60 corruption level) performance:
- Accuracy: DT 0.98272 (+/- 0.01078) || SVM-RBF 0.91113 (+/- 0.08610)
- Precision: DT 0.98996 (+/- 0.01515) || SVM-RBF 0.90242 (+/- 0.09323)
- F1: DT 0.99042 (+/- 0.00631) || SVM-RBF 0.94806 (+/- 0.05248) 
