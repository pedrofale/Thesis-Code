Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 2326.778542
Pre-training layer 0, epoch 1, cost 364.886902
Pre-training layer 0, epoch 2, cost 249.023790
Pre-training layer 0, epoch 3, cost 202.797376
Pre-training layer 0, epoch 4, cost 177.947765
Pre-training layer 0, epoch 5, cost 162.471127
Pre-training layer 0, epoch 6, cost 151.923714
Pre-training layer 0, epoch 7, cost 144.299021
Pre-training layer 0, epoch 8, cost 138.533434
Pre-training layer 0, epoch 9, cost 134.031075
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.61842 acc, 0.61511 prec, 0.74672 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 2335.923434
Pre-training layer 0, epoch 1, cost 364.718035
Pre-training layer 0, epoch 2, cost 248.196337
Pre-training layer 0, epoch 3, cost 201.725798
Pre-training layer 0, epoch 4, cost 176.727376
Pre-training layer 0, epoch 5, cost 161.152924
Pre-training layer 0, epoch 6, cost 150.546945
Pre-training layer 0, epoch 7, cost 142.872278
Pre-training layer 0, epoch 8, cost 137.072350
Pre-training layer 0, epoch 9, cost 132.538586
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.57895 acc, 0.58214 prec, 0.71806 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 2301.736114
Pre-training layer 0, epoch 1, cost 359.856581
Pre-training layer 0, epoch 2, cost 245.573654
Pre-training layer 0, epoch 3, cost 200.008067
Pre-training layer 0, epoch 4, cost 175.491265
Pre-training layer 0, epoch 5, cost 160.227282
Pre-training layer 0, epoch 6, cost 149.827293
Pre-training layer 0, epoch 7, cost 142.306879
Pre-training layer 0, epoch 8, cost 136.623523
Pre-training layer 0, epoch 9, cost 132.179524
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.62500 acc, 0.61255 prec, 0.74439 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 2297.578155
Pre-training layer 0, epoch 1, cost 358.423258
Pre-training layer 0, epoch 2, cost 244.273486
Pre-training layer 0, epoch 3, cost 198.737451
Pre-training layer 0, epoch 4, cost 174.249476
Pre-training layer 0, epoch 5, cost 158.994573
Pre-training layer 0, epoch 6, cost 148.602330
Pre-training layer 0, epoch 7, cost 141.081795
Pre-training layer 0, epoch 8, cost 135.401873
Pre-training layer 0, epoch 9, cost 130.961531
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.57096 acc, 0.56410 prec, 0.70320 f1
SDA (1 layer(s), 0.30 corruption level) performance:
- Accuracy: DT 0.59833 (+/- 0.04733) || SVM-RBF 0.11358 (+/- 0.02520)
- Precision: DT 0.59347 (+/- 0.04269) || SVM-RBF 0.02266 (+/- 0.01718)
- F1: DT 0.72809 (+/- 0.03652) || SVM-RBF 0.04418 (+/- 0.03291) 
