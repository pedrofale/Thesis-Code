Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 234.701858
Pre-training layer 0, epoch 1, cost 103.646065
Pre-training layer 0, epoch 2, cost 101.837124
Pre-training layer 0, epoch 3, cost 101.134272
Pre-training layer 0, epoch 4, cost 100.763196
Pre-training layer 0, epoch 5, cost 100.535431
Pre-training layer 0, epoch 6, cost 100.382240
Pre-training layer 0, epoch 7, cost 100.272629
Pre-training layer 0, epoch 8, cost 100.190604
Pre-training layer 0, epoch 9, cost 100.127098
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.71382 acc, 0.72302 prec, 0.82209 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 233.894963
Pre-training layer 0, epoch 1, cost 101.945953
Pre-training layer 0, epoch 2, cost 100.122173
Pre-training layer 0, epoch 3, cost 99.413421
Pre-training layer 0, epoch 4, cost 99.039141
Pre-training layer 0, epoch 5, cost 98.809351
Pre-training layer 0, epoch 6, cost 98.654760
Pre-training layer 0, epoch 7, cost 98.544119
Pre-training layer 0, epoch 8, cost 98.461304
Pre-training layer 0, epoch 9, cost 98.397170
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.69737 acc, 0.69286 prec, 0.80833 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 232.166513
Pre-training layer 0, epoch 1, cost 102.237260
Pre-training layer 0, epoch 2, cost 100.450864
Pre-training layer 0, epoch 3, cost 99.757293
Pre-training layer 0, epoch 4, cost 99.391276
Pre-training layer 0, epoch 5, cost 99.166682
Pre-training layer 0, epoch 6, cost 99.015660
Pre-training layer 0, epoch 7, cost 98.907621
Pre-training layer 0, epoch 8, cost 98.826786
Pre-training layer 0, epoch 9, cost 98.764210
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.83553 acc, 0.85240 prec, 0.90234 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 231.369272
Pre-training layer 0, epoch 1, cost 100.994357
Pre-training layer 0, epoch 2, cost 99.211062
Pre-training layer 0, epoch 3, cost 98.517991
Pre-training layer 0, epoch 4, cost 98.152036
Pre-training layer 0, epoch 5, cost 97.927400
Pre-training layer 0, epoch 6, cost 97.776307
Pre-training layer 0, epoch 7, cost 97.668193
Pre-training layer 0, epoch 8, cost 97.587286
Pre-training layer 0, epoch 9, cost 97.524643
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.74917 acc, 0.74359 prec, 0.84232 f1
SDA (1 layer(s), 0.00 corruption level) performance:
- Accuracy: DT 0.74897 (+/- 0.10673) || SVM-RBF 0.19252 (+/- 0.17943)
- Precision: DT 0.75297 (+/- 0.12035) || SVM-RBF 0.11017 (+/- 0.22341)
- F1: DT 0.84377 (+/- 0.07183) || SVM-RBF 0.17962 (+/- 0.36242) 
