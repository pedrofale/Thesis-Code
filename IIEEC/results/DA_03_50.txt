Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 227.175047
Pre-training layer 0, epoch 1, cost 103.646095
Pre-training layer 0, epoch 2, cost 101.837260
Pre-training layer 0, epoch 3, cost 101.134439
Pre-training layer 0, epoch 4, cost 100.763376
Pre-training layer 0, epoch 5, cost 100.535620
Pre-training layer 0, epoch 6, cost 100.382434
Pre-training layer 0, epoch 7, cost 100.272827
Pre-training layer 0, epoch 8, cost 100.190805
Pre-training layer 0, epoch 9, cost 100.127302
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.75987 acc, 0.76619 prec, 0.85371 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 226.075729
Pre-training layer 0, epoch 1, cost 101.945968
Pre-training layer 0, epoch 2, cost 100.122290
Pre-training layer 0, epoch 3, cost 99.413568
Pre-training layer 0, epoch 4, cost 99.039301
Pre-training layer 0, epoch 5, cost 98.809519
Pre-training layer 0, epoch 6, cost 98.654933
Pre-training layer 0, epoch 7, cost 98.544296
Pre-training layer 0, epoch 8, cost 98.461483
Pre-training layer 0, epoch 9, cost 98.397352
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.74342 acc, 0.74286 prec, 0.84211 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 227.898375
Pre-training layer 0, epoch 1, cost 102.237337
Pre-training layer 0, epoch 2, cost 100.451055
Pre-training layer 0, epoch 3, cost 99.757519
Pre-training layer 0, epoch 4, cost 99.391518
Pre-training layer 0, epoch 5, cost 99.166934
Pre-training layer 0, epoch 6, cost 99.015920
Pre-training layer 0, epoch 7, cost 98.907886
Pre-training layer 0, epoch 8, cost 98.827055
Pre-training layer 0, epoch 9, cost 98.764482
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.77303 acc, 0.79336 prec, 0.86172 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 220.122187
Pre-training layer 0, epoch 1, cost 100.994394
Pre-training layer 0, epoch 2, cost 99.211323
Pre-training layer 0, epoch 3, cost 98.518317
Pre-training layer 0, epoch 4, cost 98.152393
Pre-training layer 0, epoch 5, cost 97.927776
Pre-training layer 0, epoch 6, cost 97.776696
Pre-training layer 0, epoch 7, cost 97.668591
Pre-training layer 0, epoch 8, cost 97.587690
Pre-training layer 0, epoch 9, cost 97.525054
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.70627 acc, 0.71429 prec, 0.81420 f1
SDA (1 layer(s), 0.30 corruption level) performance:
- Accuracy: DT 0.74565 (+/- 0.05007) || SVM-RBF 0.29220 (+/- 0.03644)
- Precision: DT 0.75417 (+/- 0.05830) || SVM-RBF 0.22690 (+/- 0.04083)
- F1: DT 0.84293 (+/- 0.03600) || SVM-RBF 0.36720 (+/- 0.05324) 
