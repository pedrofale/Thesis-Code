Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 204.347154
Pre-training layer 0, epoch 1, cost 129.409357
Pre-training layer 0, epoch 2, cost 123.599519
Pre-training layer 0, epoch 3, cost 119.493488
Pre-training layer 0, epoch 4, cost 116.694593
Pre-training layer 0, epoch 5, cost 114.302718
Pre-training layer 0, epoch 6, cost 112.670453
Pre-training layer 0, epoch 7, cost 111.244699
Pre-training layer 0, epoch 8, cost 110.096947
Pre-training layer 0, epoch 9, cost 109.217146
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.97697 acc, 0.98561 prec, 0.98739 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 149.372583
Pre-training layer 0, epoch 1, cost 105.639211
Pre-training layer 0, epoch 2, cost 102.485132
Pre-training layer 0, epoch 3, cost 100.897058
Pre-training layer 0, epoch 4, cost 100.186073
Pre-training layer 0, epoch 5, cost 99.471923
Pre-training layer 0, epoch 6, cost 99.018871
Pre-training layer 0, epoch 7, cost 98.755873
Pre-training layer 0, epoch 8, cost 98.473634
Pre-training layer 0, epoch 9, cost 98.224004
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98026 acc, 0.99286 prec, 0.98932 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 150.675390
Pre-training layer 0, epoch 1, cost 106.115525
Pre-training layer 0, epoch 2, cost 102.865110
Pre-training layer 0, epoch 3, cost 101.412937
Pre-training layer 0, epoch 4, cost 100.544561
Pre-training layer 0, epoch 5, cost 99.967140
Pre-training layer 0, epoch 6, cost 99.591232
Pre-training layer 0, epoch 7, cost 99.250515
Pre-training layer 0, epoch 8, cost 98.938317
Pre-training layer 0, epoch 9, cost 98.517992
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.96053 acc, 0.97786 prec, 0.97786 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 144.108081
Pre-training layer 0, epoch 1, cost 104.504480
Pre-training layer 0, epoch 2, cost 101.582980
Pre-training layer 0, epoch 3, cost 100.204729
Pre-training layer 0, epoch 4, cost 99.248310
Pre-training layer 0, epoch 5, cost 98.586609
Pre-training layer 0, epoch 6, cost 98.076994
Pre-training layer 0, epoch 7, cost 97.806911
Pre-training layer 0, epoch 8, cost 97.675788
Pre-training layer 0, epoch 9, cost 97.443755
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.98020 acc, 0.99634 prec, 0.98909 f1
SDA (1 layer(s), 0.30 corruption level) performance:
- Accuracy: DT 0.97449 (+/- 0.01634) || SVM-RBF 0.93171 (+/- 0.04880)
- Precision: DT 0.98817 (+/- 0.01420) || SVM-RBF 0.92492 (+/- 0.05211)
- F1: DT 0.98592 (+/- 0.00942) || SVM-RBF 0.96080 (+/- 0.02844) 
