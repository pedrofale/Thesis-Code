Removing cached data...
done
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
Oversampling the training set...
--- iteration no. 1 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 231.943625
Pre-training layer 0, epoch 1, cost 103.646090
Pre-training layer 0, epoch 2, cost 101.837187
Pre-training layer 0, epoch 3, cost 101.134347
Pre-training layer 0, epoch 4, cost 100.763276
Pre-training layer 0, epoch 5, cost 100.535514
Pre-training layer 0, epoch 6, cost 100.382326
Pre-training layer 0, epoch 7, cost 100.272715
Pre-training layer 0, epoch 8, cost 100.190692
Pre-training layer 0, epoch 9, cost 100.127187
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.74342 acc, 0.74820 prec, 0.84211 f1
--- iteration no. 2 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 233.220878
Pre-training layer 0, epoch 1, cost 101.945966
Pre-training layer 0, epoch 2, cost 100.122218
Pre-training layer 0, epoch 3, cost 99.413475
Pre-training layer 0, epoch 4, cost 99.039199
Pre-training layer 0, epoch 5, cost 98.809412
Pre-training layer 0, epoch 6, cost 98.654822
Pre-training layer 0, epoch 7, cost 98.544183
Pre-training layer 0, epoch 8, cost 98.461368
Pre-training layer 0, epoch 9, cost 98.397235
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.78289 acc, 0.77857 prec, 0.86853 f1
--- iteration no. 3 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 231.279991
Pre-training layer 0, epoch 1, cost 102.237276
Pre-training layer 0, epoch 2, cost 100.450957
Pre-training layer 0, epoch 3, cost 99.757409
Pre-training layer 0, epoch 4, cost 99.391402
Pre-training layer 0, epoch 5, cost 99.166814
Pre-training layer 0, epoch 6, cost 99.015796
Pre-training layer 0, epoch 7, cost 98.907761
Pre-training layer 0, epoch 8, cost 98.826929
Pre-training layer 0, epoch 9, cost 98.764354
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.77961 acc, 0.80443 prec, 0.86680 f1
--- iteration no. 4 ---
building SDA...
getting the pretraining functions...
pre-training the SDA...
Pre-training layer 0, epoch 0, cost 229.196260
Pre-training layer 0, epoch 1, cost 100.994411
Pre-training layer 0, epoch 2, cost 99.211220
Pre-training layer 0, epoch 3, cost 98.518180
Pre-training layer 0, epoch 4, cost 98.152241
Pre-training layer 0, epoch 5, cost 97.927613
Pre-training layer 0, epoch 6, cost 97.776529
Pre-training layer 0, epoch 7, cost 97.668421
Pre-training layer 0, epoch 8, cost 97.587516
Pre-training layer 0, epoch 9, cost 97.524879
getting the finetuning functions...
training decision tree...
evaluating decision tree...
DT 0.78218 acc, 0.79487 prec, 0.86800 f1
SDA (1 layer(s), 0.10 corruption level) performance:
- Accuracy: DT 0.77202 (+/- 0.03312) || SVM-RBF 0.23446 (+/- 0.15853)
- Precision: DT 0.78152 (+/- 0.04268) || SVM-RBF 0.16091 (+/- 0.18996)
- F1: DT 0.86136 (+/- 0.02227) || SVM-RBF 0.26295 (+/- 0.30812) 
